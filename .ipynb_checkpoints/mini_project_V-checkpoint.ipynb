{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Identifying Duplicate Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over 100 million people visit Quora every month, so it's no surprise that many people ask similar (or the same) questions. Various questions with the same intent can cause people to spend extra time searching for the best answer to their question, and results in members answering multiple versions of the same question. Quora uses random forest to identify duplicated questions to provide a better experience to active seekers and writers, and offer more value to both of these groups in the long term.\n",
    "Follow the steps outlined below to build the appropriate classifier model. \n",
    "\n",
    "\n",
    "Steps:\n",
    "- Download data\n",
    "- Exploration\n",
    "- Cleaning\n",
    "- Feature Engineering\n",
    "- Modeling\n",
    "\n",
    "By the end of this project you should have **a presentation that describes the model you built** and its **performance**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/mnicn/local_documents/lighthouse-data-notes/NLP-Project/data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: There is no designated test.csv file. The train.csv file is the entire dataset. Part of the data in the train.csv file should be set aside to act as the final testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    255027\n",
       "1    149263\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check number which are duplicates\n",
    "df[\"is_duplicate\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404290 entries, 0 to 404289\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   id            404290 non-null  int64 \n",
      " 1   qid1          404290 non-null  int64 \n",
      " 2   qid2          404290 non-null  int64 \n",
      " 3   question1     404289 non-null  object\n",
      " 4   question2     404288 non-null  object\n",
      " 5   is_duplicate  404290 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 18.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows with blank values (there are only a very small number)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404287, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 404287 entries, 0 to 404289\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   id            404287 non-null  int64 \n",
      " 1   qid1          404287 non-null  int64 \n",
      " 2   qid2          404287 non-null  int64 \n",
      " 3   question1     404287 non-null  object\n",
      " 4   question2     404287 non-null  object\n",
      " 5   is_duplicate  404287 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 21.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    255024\n",
       "1    149263\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"is_duplicate\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n",
    "\n",
    "- Tokenization\n",
    "- Stopwords cleaning\n",
    "- Removing punctuation\n",
    "- Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mnicn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\mnicn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mnicn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mnicn\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#import required packages for cleaning\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import string\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENGstopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define cleaning function\n",
    "\n",
    "def clean(text):\n",
    "    \n",
    "    # remove punctuation    \n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "\n",
    "    # tokenize words\n",
    "    tokens = text.split()\n",
    "\n",
    "    # remove all stopwords\n",
    "    tokens_no_stopwords = [word for word in tokens if word not in ENGstopwords]\n",
    "\n",
    "    # lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens_n = [lemmatizer.lemmatize(token) for token in tokens_no_stopwords]\n",
    "    lemmatized_tokens_v = [lemmatizer.lemmatize(token, pos =\"v\") for token in lemmatized_tokens_n]\n",
    "    lemmatized_tokens_a = [lemmatizer.lemmatize(token, pos =\"a\") for token in lemmatized_tokens_v]\n",
    "    lemmatized_tokens_r = [lemmatizer.lemmatize(token, pos =\"r\") for token in lemmatized_tokens_a]\n",
    "    lemmatized_tokens_s = [lemmatizer.lemmatize(token, pos =\"s\") for token in lemmatized_tokens_r]\n",
    "        \n",
    "    return lemmatized_tokens_s\n",
    "\n",
    "\n",
    "df['q1_clean'] = df['question1'].apply(lambda x: clean(x.lower()))\n",
    "df['q2_clean'] = df['question2'].apply(lambda x: clean(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_clean</th>\n",
       "      <th>q2_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>[step, step, guide, invest, share, market, india]</td>\n",
       "      <td>[step, step, guide, invest, share, market]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>[story, kohinoor, kohinoor, diamond]</td>\n",
       "      <td>[would, happen, indian, government, steal, koh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>[increase, speed, internet, connection, use, vpn]</td>\n",
       "      <td>[internet, speed, increase, hack, dns]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>[mentally, lonely, solve]</td>\n",
       "      <td>[find, remainder, math2324math, divide, 2423]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>[one, dissolve, water, quikly, sugar, salt, me...</td>\n",
       "      <td>[fish, would, survive, salt, water]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "1  What would happen if the Indian government sto...             0   \n",
       "2  How can Internet speed be increased by hacking...             0   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0   \n",
       "4            Which fish would survive in salt water?             0   \n",
       "\n",
       "                                            q1_clean  \\\n",
       "0  [step, step, guide, invest, share, market, india]   \n",
       "1               [story, kohinoor, kohinoor, diamond]   \n",
       "2  [increase, speed, internet, connection, use, vpn]   \n",
       "3                          [mentally, lonely, solve]   \n",
       "4  [one, dissolve, water, quikly, sugar, salt, me...   \n",
       "\n",
       "                                            q2_clean  \n",
       "0         [step, step, guide, invest, share, market]  \n",
       "1  [would, happen, indian, government, steal, koh...  \n",
       "2             [internet, speed, increase, hack, dns]  \n",
       "3      [find, remainder, math2324math, divide, 2423]  \n",
       "4                [fish, would, survive, salt, water]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(df.iloc[0,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "- tf-idf\n",
    "- word2vec\n",
    "- word count\n",
    "- number of the same words in both questions\n",
    "- ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 1: tf-idf Cosine Similarity Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a string from the pre-processed text tokens\n",
    "\n",
    "q1_strings = []\n",
    "q2_strings = []\n",
    "i = 0\n",
    "\n",
    "while i < df.shape[0]:\n",
    "    q1_strings.append(' '.join(df.iloc[i,6]))\n",
    "    q2_strings.append(' '.join(df.iloc[i,7]))\n",
    "    i += 1\n",
    "\n",
    "df['q1_strings'] = q1_strings\n",
    "df['q2_strings'] = q2_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            step step guide invest share market india\n",
       "1                      story kohinoor kohinoor diamond\n",
       "2           increase speed internet connection use vpn\n",
       "3                                mentally lonely solve\n",
       "4    one dissolve water quikly sugar salt methane c...\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create corpus\n",
    " \n",
    "corpus = pd.concat([df['q1_strings'], df['q2_strings']])\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define cleaning function\n",
    "\n",
    "def clean(text):\n",
    "    \n",
    "    # remove punctuation    \n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "\n",
    "    # tokenize words\n",
    "    tokens = text.split()\n",
    "\n",
    "    # remove all stopwords\n",
    "    tokens_no_stopwords = [word for word in tokens if word not in ENGstopwords]\n",
    "\n",
    "    # lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens_n = [lemmatizer.lemmatize(token) for token in tokens_no_stopwords]\n",
    "    lemmatized_tokens_v = [lemmatizer.lemmatize(token, pos =\"v\") for token in lemmatized_tokens_n]\n",
    "    lemmatized_tokens_a = [lemmatizer.lemmatize(token, pos =\"a\") for token in lemmatized_tokens_v]\n",
    "    lemmatized_tokens_r = [lemmatizer.lemmatize(token, pos =\"r\") for token in lemmatized_tokens_a]\n",
    "    lemmatized_tokens_s = [lemmatizer.lemmatize(token, pos =\"s\") for token in lemmatized_tokens_r]\n",
    "        \n",
    "    return lemmatized_tokens_s\n",
    "\n",
    "\n",
    "df['q1_clean'] = df['question1'].apply(lambda x: clean(x.lower()))\n",
    "df['q2_clean'] = df['question2'].apply(lambda x: clean(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instantiate TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform strings to vector\n",
    "\n",
    "q1_vecs = vectorizer.transform(df['q1_strings'])\n",
    "q2_vecs = vectorizer.transform(df['q2_strings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x94166 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1_vecs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create a list of cosine similarities\n",
    "\n",
    "cosine_similarity_list = []\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "for i in range(len(df)):\n",
    "       \n",
    "        cosine_similarity_list.append(cosine_similarity(q1_vecs[i], q2_vecs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "cosine_similarity = []\n",
    "\n",
    "while i < df.shape[0]:\n",
    "    cosine_similarity.append(cosine_similarity_list[i][0][0])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cosine_similarity'] = cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"processed_questions_w_feat1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 2: Number of Same Words in Both Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sq_set_1 = []\n",
    "# sq_set_2 = []\n",
    "# i = 0\n",
    "\n",
    "# while i < df.shape[0]:\n",
    "#     sq_set_1.append(set(df.iloc[i,6]))\n",
    "#     sq_set_2.append(set(df.iloc[i,7]))\n",
    "#     i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['sq_set_1'] = sq_set_1\n",
    "# df['sq_set_2'] = sq_set_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_clean</th>\n",
       "      <th>q2_clean</th>\n",
       "      <th>q1_strings</th>\n",
       "      <th>q2_strings</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>[step, step, guide, invest, share, market, india]</td>\n",
       "      <td>[step, step, guide, invest, share, market]</td>\n",
       "      <td>step step guide invest share market india</td>\n",
       "      <td>step step guide invest share market</td>\n",
       "      <td>0.978631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>[story, kohinoor, kohinoor, diamond]</td>\n",
       "      <td>[would, happen, indian, government, steal, koh...</td>\n",
       "      <td>story kohinoor kohinoor diamond</td>\n",
       "      <td>would happen indian government steal kohinoor ...</td>\n",
       "      <td>0.822231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "1  What would happen if the Indian government sto...             0   \n",
       "\n",
       "                                            q1_clean  \\\n",
       "0  [step, step, guide, invest, share, market, india]   \n",
       "1               [story, kohinoor, kohinoor, diamond]   \n",
       "\n",
       "                                            q2_clean  \\\n",
       "0         [step, step, guide, invest, share, market]   \n",
       "1  [would, happen, indian, government, steal, koh...   \n",
       "\n",
       "                                  q1_strings  \\\n",
       "0  step step guide invest share market india   \n",
       "1            story kohinoor kohinoor diamond   \n",
       "\n",
       "                                          q2_strings  cosine_similarity  \n",
       "0                step step guide invest share market           0.978631  \n",
       "1  would happen indian government steal kohinoor ...           0.822231  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_len = []\n",
    "i = 0\n",
    "\n",
    "while i < df.shape[0]:\n",
    "    common_len.append(len((set(df.iloc[i,6]).intersection(set(df.iloc[i,7])))))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['common_len'] = common_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_clean</th>\n",
       "      <th>q2_clean</th>\n",
       "      <th>q1_strings</th>\n",
       "      <th>q2_strings</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>common_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>83750</th>\n",
       "      <td>83750</td>\n",
       "      <td>71619</td>\n",
       "      <td>314</td>\n",
       "      <td>Can I upload part of anime videos on YouTube a...</td>\n",
       "      <td>How do you upload movies on YouTube and moneti...</td>\n",
       "      <td>1</td>\n",
       "      <td>[upload, part, anime, video, youtube, monetize...</td>\n",
       "      <td>[upload, movie, youtube, monetize, issue, copy...</td>\n",
       "      <td>upload part anime video youtube monetize witho...</td>\n",
       "      <td>upload movie youtube monetize issue copyright</td>\n",
       "      <td>0.775899</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184792</th>\n",
       "      <td>184792</td>\n",
       "      <td>282233</td>\n",
       "      <td>282234</td>\n",
       "      <td>What of are some good reasons to why you shoul...</td>\n",
       "      <td>How stupid is the American mainstream media?</td>\n",
       "      <td>0</td>\n",
       "      <td>[good, reason, shouldnt, trust, mainstream, me...</td>\n",
       "      <td>[stupid, american, mainstream, medium]</td>\n",
       "      <td>good reason shouldnt trust mainstream medium</td>\n",
       "      <td>stupid american mainstream medium</td>\n",
       "      <td>0.498374</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24879</th>\n",
       "      <td>24879</td>\n",
       "      <td>46425</td>\n",
       "      <td>36801</td>\n",
       "      <td>What is the surgical strike?</td>\n",
       "      <td>What do you mean by surgical strike?</td>\n",
       "      <td>1</td>\n",
       "      <td>[surgical, strike]</td>\n",
       "      <td>[mean, surgical, strike]</td>\n",
       "      <td>surgical strike</td>\n",
       "      <td>mean surgical strike</td>\n",
       "      <td>0.910564</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234196</th>\n",
       "      <td>234196</td>\n",
       "      <td>344638</td>\n",
       "      <td>85979</td>\n",
       "      <td>How can I be happy living with people who judg...</td>\n",
       "      <td>How can I be happy living with people who judg...</td>\n",
       "      <td>1</td>\n",
       "      <td>[happy, live, people, judge, action, wrong]</td>\n",
       "      <td>[happy, live, people, judge, action, wrong]</td>\n",
       "      <td>happy live people judge action wrong</td>\n",
       "      <td>happy live people judge action wrong</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272050</th>\n",
       "      <td>272050</td>\n",
       "      <td>1098</td>\n",
       "      <td>390254</td>\n",
       "      <td>What are some Interesting mobile apps?</td>\n",
       "      <td>What are the best mobile apps to have?</td>\n",
       "      <td>0</td>\n",
       "      <td>[interest, mobile, apps]</td>\n",
       "      <td>[best, mobile, apps]</td>\n",
       "      <td>interest mobile apps</td>\n",
       "      <td>best mobile apps</td>\n",
       "      <td>0.788308</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79029</th>\n",
       "      <td>79029</td>\n",
       "      <td>134649</td>\n",
       "      <td>134650</td>\n",
       "      <td>Is what people share more important than what ...</td>\n",
       "      <td>Why does boost YouTube views?</td>\n",
       "      <td>0</td>\n",
       "      <td>[people, share, important, divide]</td>\n",
       "      <td>[boost, youtube, view]</td>\n",
       "      <td>people share important divide</td>\n",
       "      <td>boost youtube view</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78224</th>\n",
       "      <td>78224</td>\n",
       "      <td>133420</td>\n",
       "      <td>133421</td>\n",
       "      <td>Something thing you've seen?</td>\n",
       "      <td>What is the strangest thing you've ever seen?</td>\n",
       "      <td>0</td>\n",
       "      <td>[something, thing, youve, see]</td>\n",
       "      <td>[strange, thing, youve, ever, see]</td>\n",
       "      <td>something thing youve see</td>\n",
       "      <td>strange thing youve ever see</td>\n",
       "      <td>0.607901</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24481</th>\n",
       "      <td>24481</td>\n",
       "      <td>45730</td>\n",
       "      <td>45731</td>\n",
       "      <td>What are some good Korean horror films out rig...</td>\n",
       "      <td>What are some of the best Korean horror movies?</td>\n",
       "      <td>1</td>\n",
       "      <td>[good, korean, horror, film, right]</td>\n",
       "      <td>[best, korean, horror, movie]</td>\n",
       "      <td>good korean horror film right</td>\n",
       "      <td>best korean horror movie</td>\n",
       "      <td>0.653902</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80150</th>\n",
       "      <td>80150</td>\n",
       "      <td>35737</td>\n",
       "      <td>107663</td>\n",
       "      <td>How can I add my profile picture on Qoura?</td>\n",
       "      <td>How do I change profile picture in Quora?</td>\n",
       "      <td>1</td>\n",
       "      <td>[add, profile, picture, qoura]</td>\n",
       "      <td>[change, profile, picture, quora]</td>\n",
       "      <td>add profile picture qoura</td>\n",
       "      <td>change profile picture quora</td>\n",
       "      <td>0.486711</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23396</th>\n",
       "      <td>23396</td>\n",
       "      <td>43821</td>\n",
       "      <td>43822</td>\n",
       "      <td>If you could live in a movie, what movie would...</td>\n",
       "      <td>If you could live in a movie, which movie woul...</td>\n",
       "      <td>1</td>\n",
       "      <td>[could, live, movie, movie, would]</td>\n",
       "      <td>[could, live, movie, movie, would, choose]</td>\n",
       "      <td>could live movie movie would</td>\n",
       "      <td>could live movie movie would choose</td>\n",
       "      <td>0.899678</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2  \\\n",
       "83750    83750   71619     314   \n",
       "184792  184792  282233  282234   \n",
       "24879    24879   46425   36801   \n",
       "234196  234196  344638   85979   \n",
       "272050  272050    1098  390254   \n",
       "79029    79029  134649  134650   \n",
       "78224    78224  133420  133421   \n",
       "24481    24481   45730   45731   \n",
       "80150    80150   35737  107663   \n",
       "23396    23396   43821   43822   \n",
       "\n",
       "                                                question1  \\\n",
       "83750   Can I upload part of anime videos on YouTube a...   \n",
       "184792  What of are some good reasons to why you shoul...   \n",
       "24879                        What is the surgical strike?   \n",
       "234196  How can I be happy living with people who judg...   \n",
       "272050             What are some Interesting mobile apps?   \n",
       "79029   Is what people share more important than what ...   \n",
       "78224                        Something thing you've seen?   \n",
       "24481   What are some good Korean horror films out rig...   \n",
       "80150          How can I add my profile picture on Qoura?   \n",
       "23396   If you could live in a movie, what movie would...   \n",
       "\n",
       "                                                question2  is_duplicate  \\\n",
       "83750   How do you upload movies on YouTube and moneti...             1   \n",
       "184792       How stupid is the American mainstream media?             0   \n",
       "24879                What do you mean by surgical strike?             1   \n",
       "234196  How can I be happy living with people who judg...             1   \n",
       "272050             What are the best mobile apps to have?             0   \n",
       "79029                       Why does boost YouTube views?             0   \n",
       "78224       What is the strangest thing you've ever seen?             0   \n",
       "24481     What are some of the best Korean horror movies?             1   \n",
       "80150           How do I change profile picture in Quora?             1   \n",
       "23396   If you could live in a movie, which movie woul...             1   \n",
       "\n",
       "                                                 q1_clean  \\\n",
       "83750   [upload, part, anime, video, youtube, monetize...   \n",
       "184792  [good, reason, shouldnt, trust, mainstream, me...   \n",
       "24879                                  [surgical, strike]   \n",
       "234196        [happy, live, people, judge, action, wrong]   \n",
       "272050                           [interest, mobile, apps]   \n",
       "79029                  [people, share, important, divide]   \n",
       "78224                      [something, thing, youve, see]   \n",
       "24481                 [good, korean, horror, film, right]   \n",
       "80150                      [add, profile, picture, qoura]   \n",
       "23396                  [could, live, movie, movie, would]   \n",
       "\n",
       "                                                 q2_clean  \\\n",
       "83750   [upload, movie, youtube, monetize, issue, copy...   \n",
       "184792             [stupid, american, mainstream, medium]   \n",
       "24879                            [mean, surgical, strike]   \n",
       "234196        [happy, live, people, judge, action, wrong]   \n",
       "272050                               [best, mobile, apps]   \n",
       "79029                              [boost, youtube, view]   \n",
       "78224                  [strange, thing, youve, ever, see]   \n",
       "24481                       [best, korean, horror, movie]   \n",
       "80150                   [change, profile, picture, quora]   \n",
       "23396          [could, live, movie, movie, would, choose]   \n",
       "\n",
       "                                               q1_strings  \\\n",
       "83750   upload part anime video youtube monetize witho...   \n",
       "184792       good reason shouldnt trust mainstream medium   \n",
       "24879                                     surgical strike   \n",
       "234196               happy live people judge action wrong   \n",
       "272050                               interest mobile apps   \n",
       "79029                       people share important divide   \n",
       "78224                           something thing youve see   \n",
       "24481                       good korean horror film right   \n",
       "80150                           add profile picture qoura   \n",
       "23396                        could live movie movie would   \n",
       "\n",
       "                                           q2_strings  cosine_similarity  \\\n",
       "83750   upload movie youtube monetize issue copyright           0.775899   \n",
       "184792              stupid american mainstream medium           0.498374   \n",
       "24879                            mean surgical strike           0.910564   \n",
       "234196           happy live people judge action wrong           1.000000   \n",
       "272050                               best mobile apps           0.788308   \n",
       "79029                              boost youtube view           0.000000   \n",
       "78224                    strange thing youve ever see           0.607901   \n",
       "24481                        best korean horror movie           0.653902   \n",
       "80150                    change profile picture quora           0.486711   \n",
       "23396             could live movie movie would choose           0.899678   \n",
       "\n",
       "        common_len  \n",
       "83750            5  \n",
       "184792           2  \n",
       "24879            2  \n",
       "234196           6  \n",
       "272050           2  \n",
       "79029            0  \n",
       "78224            3  \n",
       "24481            2  \n",
       "80150            2  \n",
       "23396            4  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"processed_questions_w_feat2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 3: Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# need to count words INCLUDING stopwords! \n",
    "# create cleaning function which creates a list of words including stopwords and find len. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define cleaning function\n",
    "\n",
    "def clean_keep_stopwords(text):\n",
    "    \n",
    "    # remove punctuation    \n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "\n",
    "    # tokenize words\n",
    "    tokens = text.split()\n",
    "\n",
    "#     # remove all stopwords\n",
    "#     tokens_no_stopwords = [word for word in tokens if word not in ENGstopwords]\n",
    "\n",
    "#     # lemmatize\n",
    "#     lemmatizer = WordNetLemmatizer()\n",
    "#     lemmatized_tokens_n = [lemmatizer.lemmatize(token) for token in tokens_no_stopwords]\n",
    "#     lemmatized_tokens_v = [lemmatizer.lemmatize(token, pos =\"v\") for token in lemmatized_tokens_n]\n",
    "#     lemmatized_tokens_a = [lemmatizer.lemmatize(token, pos =\"a\") for token in lemmatized_tokens_v]\n",
    "#     lemmatized_tokens_r = [lemmatizer.lemmatize(token, pos =\"r\") for token in lemmatized_tokens_a]\n",
    "#     lemmatized_tokens_s = [lemmatizer.lemmatize(token, pos =\"s\") for token in lemmatized_tokens_r]\n",
    "        \n",
    "    return len(tokens)\n",
    "\n",
    "\n",
    "df['q1_raw_tokens'] = df['question1'].apply(lambda x: clean_keep_stopwords(x.lower()))\n",
    "df['q2_raw_tokens'] = df['question2'].apply(lambda x: clean_keep_stopwords(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['difference_word_count'] = df['q1_raw_tokens']/df['q2_raw_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_clean</th>\n",
       "      <th>q2_clean</th>\n",
       "      <th>q1_strings</th>\n",
       "      <th>q2_strings</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>common_len</th>\n",
       "      <th>q1_raw_tokens</th>\n",
       "      <th>q2_raw_tokens</th>\n",
       "      <th>difference_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>[step, step, guide, invest, share, market, india]</td>\n",
       "      <td>[step, step, guide, invest, share, market]</td>\n",
       "      <td>step step guide invest share market india</td>\n",
       "      <td>step step guide invest share market</td>\n",
       "      <td>0.978631</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>1.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>[story, kohinoor, kohinoor, diamond]</td>\n",
       "      <td>[would, happen, indian, government, steal, koh...</td>\n",
       "      <td>story kohinoor kohinoor diamond</td>\n",
       "      <td>would happen indian government steal kohinoor ...</td>\n",
       "      <td>0.822231</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>[increase, speed, internet, connection, use, vpn]</td>\n",
       "      <td>[internet, speed, increase, hack, dns]</td>\n",
       "      <td>increase speed internet connection use vpn</td>\n",
       "      <td>internet speed increase hack dns</td>\n",
       "      <td>0.441928</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>1.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>[mentally, lonely, solve]</td>\n",
       "      <td>[find, remainder, math2324math, divide, 2423]</td>\n",
       "      <td>mentally lonely solve</td>\n",
       "      <td>find remainder math2324math divide 2423</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>1.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>[one, dissolve, water, quikly, sugar, salt, me...</td>\n",
       "      <td>[fish, would, survive, salt, water]</td>\n",
       "      <td>one dissolve water quikly sugar salt methane c...</td>\n",
       "      <td>fish would survive salt water</td>\n",
       "      <td>0.232004</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>1.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "1  What would happen if the Indian government sto...             0   \n",
       "2  How can Internet speed be increased by hacking...             0   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0   \n",
       "4            Which fish would survive in salt water?             0   \n",
       "\n",
       "                                            q1_clean  \\\n",
       "0  [step, step, guide, invest, share, market, india]   \n",
       "1               [story, kohinoor, kohinoor, diamond]   \n",
       "2  [increase, speed, internet, connection, use, vpn]   \n",
       "3                          [mentally, lonely, solve]   \n",
       "4  [one, dissolve, water, quikly, sugar, salt, me...   \n",
       "\n",
       "                                            q2_clean  \\\n",
       "0         [step, step, guide, invest, share, market]   \n",
       "1  [would, happen, indian, government, steal, koh...   \n",
       "2             [internet, speed, increase, hack, dns]   \n",
       "3      [find, remainder, math2324math, divide, 2423]   \n",
       "4                [fish, would, survive, salt, water]   \n",
       "\n",
       "                                          q1_strings  \\\n",
       "0          step step guide invest share market india   \n",
       "1                    story kohinoor kohinoor diamond   \n",
       "2         increase speed internet connection use vpn   \n",
       "3                              mentally lonely solve   \n",
       "4  one dissolve water quikly sugar salt methane c...   \n",
       "\n",
       "                                          q2_strings  cosine_similarity  \\\n",
       "0                step step guide invest share market           0.978631   \n",
       "1  would happen indian government steal kohinoor ...           0.822231   \n",
       "2                   internet speed increase hack dns           0.441928   \n",
       "3            find remainder math2324math divide 2423           0.000000   \n",
       "4                      fish would survive salt water           0.232004   \n",
       "\n",
       "   common_len  q1_raw_tokens  q2_raw_tokens  difference_word_count  \n",
       "0           5             14             12               1.166667  \n",
       "1           2              8             13               0.615385  \n",
       "2           3             14             10               1.400000  \n",
       "3           0             11              9               1.222222  \n",
       "4           2             13              7               1.857143  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"processed_questions_w_feat3.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"processed_questions_w_feat3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 4: Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a string from the pre-processed text tokens\n",
    "\n",
    "q1_unique_tokens = []\n",
    "q2_unique_tokens = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i < df.shape[0]:\n",
    "    q1_unique_tokens.append(list(set(df.iloc[i,6])))\n",
    "    q2_unique_tokens.append(list(set(df.iloc[i,7])))\n",
    "    i += 1\n",
    "\n",
    "# print(len(q1_unique_tokens))\n",
    "# print(len(q2_unique_tokens))\n",
    "df['q1_unique_tokens'] = q1_unique_tokens\n",
    "df['q2_unique_tokens'] = q2_unique_tokens\n",
    "# print(q1_unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# Create CBoW model\n",
    "#size: output vector size\n",
    "#window: size of window for surrounding words\n",
    "#min_count: ignores all words that appear less than min_count times\n",
    "corpus_unique = pd.concat([df['q1_unique_tokens'], df['q2_unique_tokens']])\n",
    "Model_CBoW = gensim.models.Word2Vec(corpus_unique, vector_size=100, window = 3, min_count = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404167"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['q1_raw_tokens'] != 0]\n",
    "df = df[df['q2_raw_tokens'] != 0]\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create q1_w2v\n",
    "x = 0\n",
    "q1_w2v = []\n",
    "\n",
    "while x < df.shape[0]:\n",
    "    tokens = df.iloc[x,15]\n",
    "    if(len(tokens) != 0):\n",
    "        q1_w2v.append(Model_CBoW.wv[tokens[0]])\n",
    "    else:\n",
    "        q1_w2v.append(0)\n",
    "    \n",
    "    z = 1\n",
    "    \n",
    "    while z < len(tokens):\n",
    "        q1_w2v[x] = q1_w2v[x] + Model_CBoW.wv[tokens[z]]\n",
    "        \n",
    "        z += 1\n",
    "    \n",
    "    x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404167"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q1_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create q2_w2v\n",
    "x = 0\n",
    "q2_w2v = []\n",
    "\n",
    "while x < df.shape[0]:\n",
    "    tokens = df.iloc[x,16]\n",
    "    if(len(tokens) != 0):\n",
    "        q2_w2v.append(Model_CBoW.wv[tokens[0]])\n",
    "    else:\n",
    "        q2_w2v.append(0)\n",
    "    \n",
    "    z = 1\n",
    "    \n",
    "    while z < len(tokens):\n",
    "        q2_w2v[x] = q2_w2v[x] + Model_CBoW.wv[tokens[z]]\n",
    "        \n",
    "        z += 1\n",
    "    \n",
    "    x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404167"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(q2_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['q1_w2v'] = q1_w2v\n",
    "df['q2_w2v'] = q2_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_clean</th>\n",
       "      <th>q2_clean</th>\n",
       "      <th>q1_strings</th>\n",
       "      <th>q2_strings</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>common_len</th>\n",
       "      <th>q1_raw_tokens</th>\n",
       "      <th>q2_raw_tokens</th>\n",
       "      <th>difference_word_count</th>\n",
       "      <th>q1_unique_tokens</th>\n",
       "      <th>q2_unique_tokens</th>\n",
       "      <th>q1_w2v</th>\n",
       "      <th>q2_w2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>[step, step, guide, invest, share, market, india]</td>\n",
       "      <td>[step, step, guide, invest, share, market]</td>\n",
       "      <td>step step guide invest share market india</td>\n",
       "      <td>step step guide invest share market</td>\n",
       "      <td>0.978631</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>[guide, invest, india, market, share, step]</td>\n",
       "      <td>[guide, invest, market, share, step]</td>\n",
       "      <td>[0.884529, 0.7615855, 2.9755511, -6.5535207, 3...</td>\n",
       "      <td>[0.10782987, -0.22691166, 2.9367242, -5.850479...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>[story, kohinoor, kohinoor, diamond]</td>\n",
       "      <td>[would, happen, indian, government, steal, koh...</td>\n",
       "      <td>story kohinoor kohinoor diamond</td>\n",
       "      <td>would happen indian government steal kohinoor ...</td>\n",
       "      <td>0.822231</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>[story, diamond, kohinoor]</td>\n",
       "      <td>[happen, steal, government, indian, back, diam...</td>\n",
       "      <td>[-0.91223454, 0.48340303, -0.1147946, 0.684025...</td>\n",
       "      <td>[-0.15433541, -3.4760442, 1.7253506, -2.373243...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "1  What would happen if the Indian government sto...             0   \n",
       "\n",
       "                                            q1_clean  \\\n",
       "0  [step, step, guide, invest, share, market, india]   \n",
       "1               [story, kohinoor, kohinoor, diamond]   \n",
       "\n",
       "                                            q2_clean  \\\n",
       "0         [step, step, guide, invest, share, market]   \n",
       "1  [would, happen, indian, government, steal, koh...   \n",
       "\n",
       "                                  q1_strings  \\\n",
       "0  step step guide invest share market india   \n",
       "1            story kohinoor kohinoor diamond   \n",
       "\n",
       "                                          q2_strings  cosine_similarity  \\\n",
       "0                step step guide invest share market           0.978631   \n",
       "1  would happen indian government steal kohinoor ...           0.822231   \n",
       "\n",
       "   common_len  q1_raw_tokens  q2_raw_tokens  difference_word_count  \\\n",
       "0           5             14             12               1.166667   \n",
       "1           2              8             13               0.615385   \n",
       "\n",
       "                              q1_unique_tokens  \\\n",
       "0  [guide, invest, india, market, share, step]   \n",
       "1                   [story, diamond, kohinoor]   \n",
       "\n",
       "                                    q2_unique_tokens  \\\n",
       "0               [guide, invest, market, share, step]   \n",
       "1  [happen, steal, government, indian, back, diam...   \n",
       "\n",
       "                                              q1_w2v  \\\n",
       "0  [0.884529, 0.7615855, 2.9755511, -6.5535207, 3...   \n",
       "1  [-0.91223454, 0.48340303, -0.1147946, 0.684025...   \n",
       "\n",
       "                                              q2_w2v  \n",
       "0  [0.10782987, -0.22691166, 2.9367242, -5.850479...  \n",
       "1  [-0.15433541, -3.4760442, 1.7253506, -2.373243...  "
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "type_q1_w2v = []\n",
    "type_q2_w2v = []\n",
    "\n",
    "while i < df.shape[0]:\n",
    "    if type(df.iloc[i,17]) == np.ndarray:\n",
    "        type_q1_w2v.append('array')\n",
    "    else:\n",
    "        type_q1_w2v.append('int')\n",
    "        \n",
    "    if type(df.iloc[i,18]) == np.ndarray:\n",
    "        type_q2_w2v.append('array')\n",
    "    else:\n",
    "        type_q2_w2v.append('int')\n",
    "        \n",
    "    i += 1\n",
    "    \n",
    "df['type_q1_w2v'] = type_q1_w2v\n",
    "df['type_q2_w2v'] = type_q2_w2v\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['type_q1_w2v'] != 'int']\n",
    "df = df[df['type_q2_w2v'] != 'int']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "404167"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(['type_q1_w2v', 'type_q2_w2v'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_q1_w2v = np.array(q1_w2v)\n",
    "arr_q2_w2v = np.array(q2_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(arr_q1_w2v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(arr_q1_w2v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#create a list of cosine similarities\n",
    "\n",
    "cos_sim_w2v = []\n",
    "\n",
    "for i in range(df.shape[0]):\n",
    "       \n",
    "        cos_sim_w2v.append(np.dot(q1_w2v[i], q2_w2v[i]) / (np.sqrt(np.dot(q1_w2v[i], q1_w2v[i])) * np.sqrt(np.dot(q2_w2v[i], q2_w2v[i]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404167\n",
      "-0.2962244\n",
      "1.0000002\n"
     ]
    }
   ],
   "source": [
    "print(len(cos_sim_w2v))\n",
    "print(min(cos_sim_w2v))\n",
    "print(max(cos_sim_w2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cos_sim_w2v'] = cos_sim_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_clean</th>\n",
       "      <th>q2_clean</th>\n",
       "      <th>q1_strings</th>\n",
       "      <th>q2_strings</th>\n",
       "      <th>cosine_similarity</th>\n",
       "      <th>common_len</th>\n",
       "      <th>q1_raw_tokens</th>\n",
       "      <th>q2_raw_tokens</th>\n",
       "      <th>difference_word_count</th>\n",
       "      <th>q1_unique_tokens</th>\n",
       "      <th>q2_unique_tokens</th>\n",
       "      <th>q1_w2v</th>\n",
       "      <th>q2_w2v</th>\n",
       "      <th>cos_sim_w2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>[step, step, guide, invest, share, market, india]</td>\n",
       "      <td>[step, step, guide, invest, share, market]</td>\n",
       "      <td>step step guide invest share market india</td>\n",
       "      <td>step step guide invest share market</td>\n",
       "      <td>0.978631</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>[guide, invest, india, market, share, step]</td>\n",
       "      <td>[guide, invest, market, share, step]</td>\n",
       "      <td>[0.884529, 0.7615855, 2.9755511, -6.5535207, 3...</td>\n",
       "      <td>[0.10782987, -0.22691166, 2.9367242, -5.850479...</td>\n",
       "      <td>0.955502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>[story, kohinoor, kohinoor, diamond]</td>\n",
       "      <td>[would, happen, indian, government, steal, koh...</td>\n",
       "      <td>story kohinoor kohinoor diamond</td>\n",
       "      <td>would happen indian government steal kohinoor ...</td>\n",
       "      <td>0.822231</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>[story, diamond, kohinoor]</td>\n",
       "      <td>[happen, steal, government, indian, back, diam...</td>\n",
       "      <td>[-0.91223454, 0.48340303, -0.1147946, 0.684025...</td>\n",
       "      <td>[-0.15433541, -3.4760442, 1.7253506, -2.373243...</td>\n",
       "      <td>0.374187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "1  What would happen if the Indian government sto...             0   \n",
       "\n",
       "                                            q1_clean  \\\n",
       "0  [step, step, guide, invest, share, market, india]   \n",
       "1               [story, kohinoor, kohinoor, diamond]   \n",
       "\n",
       "                                            q2_clean  \\\n",
       "0         [step, step, guide, invest, share, market]   \n",
       "1  [would, happen, indian, government, steal, koh...   \n",
       "\n",
       "                                  q1_strings  \\\n",
       "0  step step guide invest share market india   \n",
       "1            story kohinoor kohinoor diamond   \n",
       "\n",
       "                                          q2_strings  cosine_similarity  \\\n",
       "0                step step guide invest share market           0.978631   \n",
       "1  would happen indian government steal kohinoor ...           0.822231   \n",
       "\n",
       "   common_len  q1_raw_tokens  q2_raw_tokens  difference_word_count  \\\n",
       "0           5             14             12               1.166667   \n",
       "1           2              8             13               0.615385   \n",
       "\n",
       "                              q1_unique_tokens  \\\n",
       "0  [guide, invest, india, market, share, step]   \n",
       "1                   [story, diamond, kohinoor]   \n",
       "\n",
       "                                    q2_unique_tokens  \\\n",
       "0               [guide, invest, market, share, step]   \n",
       "1  [happen, steal, government, indian, back, diam...   \n",
       "\n",
       "                                              q1_w2v  \\\n",
       "0  [0.884529, 0.7615855, 2.9755511, -6.5535207, 3...   \n",
       "1  [-0.91223454, 0.48340303, -0.1147946, 0.684025...   \n",
       "\n",
       "                                              q2_w2v  cos_sim_w2v  \n",
       "0  [0.10782987, -0.22691166, 2.9367242, -5.850479...     0.955502  \n",
       "1  [-0.15433541, -3.4760442, 1.7253506, -2.373243...     0.374187  "
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modeling\n",
    "\n",
    "Different modeling techniques can be used:\n",
    "\n",
    "- logistic regression\n",
    "- XGBoost\n",
    "- LSTMs\n",
    "- etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Data Preparation for Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate',\n",
       "       'q1_clean', 'q2_clean', 'q1_strings', 'q2_strings', 'cosine_similarity',\n",
       "       'common_len', 'q1_raw_tokens', 'q2_raw_tokens', 'difference_word_count',\n",
       "       'q1_unique_tokens', 'q2_unique_tokens', 'q1_w2v', 'q2_w2v',\n",
       "       'cos_sim_w2v'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prepare df for modelling\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['id', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate',\n",
    "       'q1_clean', 'q2_clean', 'q1_strings', 'q2_strings', 'tfidf_cosine_similarity',\n",
    "       'common_len', 'q1_raw_tokens', 'q2_raw_tokens', 'difference_word_count',\n",
    "       'q1_unique_tokens', 'q2_unique_tokens', 'q1_w2v', 'q2_w2v',\n",
    "       'w2v_cos_sim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate',\n",
       "       'q1_clean', 'q2_clean', 'q1_strings', 'q2_strings',\n",
       "       'tfidf_cosine_similarity', 'common_len', 'q1_raw_tokens',\n",
       "       'q2_raw_tokens', 'difference_word_count', 'q1_unique_tokens',\n",
       "       'q2_unique_tokens', 'q1_w2v', 'q2_w2v', 'w2v_cos_sim'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_cosine_similarity</th>\n",
       "      <th>common_len</th>\n",
       "      <th>difference_word_count</th>\n",
       "      <th>w2v_cos_sim</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.978631</td>\n",
       "      <td>5</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.955502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.822231</td>\n",
       "      <td>2</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.374187</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.441928</td>\n",
       "      <td>3</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>0.905253</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.222222</td>\n",
       "      <td>0.364897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.232004</td>\n",
       "      <td>2</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>0.808071</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tfidf_cosine_similarity  common_len  difference_word_count  w2v_cos_sim  \\\n",
       "0                 0.978631           5               1.166667     0.955502   \n",
       "1                 0.822231           2               0.615385     0.374187   \n",
       "2                 0.441928           3               1.400000     0.905253   \n",
       "3                 0.000000           0               1.222222     0.364897   \n",
       "4                 0.232004           2               1.857143     0.808071   \n",
       "\n",
       "   is_duplicate  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select columns to keep\n",
    "#reorder so 'is_duplicate' is last\n",
    "df_model = df[['tfidf_cosine_similarity', 'common_len', 'difference_word_count', 'w2v_cos_sim', 'is_duplicate']]\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, = df_model.iloc[:,:-1], df_model.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_cl = xgb.XGBClassifier(objective='binary:logistic',n_estimators=10, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=10, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=123, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=10, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=123, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              early_stopping_rounds=None, enable_categorical=False,\n",
       "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
       "              grow_policy='depthwise', importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
       "              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "              missing=nan, monotone_constraints='()', n_estimators=10, n_jobs=0,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=123, ...)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_cl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xg_cl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = float(np.sum(preds==y_test))/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.712225\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: %f\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifierrfc = RandomForestClassifier(random_state=1111)rfc.fit(X_train, y_train)rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9851422527239719\n",
      "Test Accuracy: 0.7146621471163125\n"
     ]
    }
   ],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Train Accuracy:\",metrics.accuracy_score(y_train, y_pred_train))\n",
    "print(\"Test Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78     51198\n",
      "           1       0.62      0.59      0.60     29636\n",
      "\n",
      "    accuracy                           0.71     80834\n",
      "   macro avg       0.69      0.69      0.69     80834\n",
      "weighted avg       0.71      0.71      0.71     80834\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    " \n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
